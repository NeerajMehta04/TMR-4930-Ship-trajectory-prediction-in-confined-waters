{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - With conventional data representation approach *lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_store_path = r'D:\\2 Thesis\\2 models\\2023.07.02 all models\\GRU_02\\prediction csv\\v1_gru_pred_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\1_10_train\\data_2019_train_X_v8_out.npy').astype('float32')\n",
    "Y_train_lat =np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\1_10_train\\data_2019_train_Y_lat_v8_out.npy').astype('float32')\n",
    "Y_train_lon =np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\1_10_train\\data_2019_train_Y_lon_v8_out.npy').astype('float32')\n",
    "\n",
    "X_val = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\11_val\\data_2019_11_X.npy').astype('float32')\n",
    "Y_val_lat = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\11_val\\data_2019_11_Y_lat.npy').astype('float32')\n",
    "Y_val_lon = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\11_val\\data_2019_11_Y_lon.npy').astype('float32')\n",
    "\n",
    "X_test = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\12_test\\data_2019_12_X.npy').astype('float32')\n",
    "Y_test_lat = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\12_test\\data_2019_12_Y_lat.npy').astype('float32')\n",
    "Y_test_lon = np.load(r'D:\\2 Thesis\\1 train datasets\\1 train geocoordinate\\12_test\\data_2019_12_Y_lon.npy').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint save - lat\n",
    "checkpoint_filepath_lat = r'D:\\2 Thesis\\2 models\\2023.07.02 all models\\GRU_02\\best model normal ds\\gru_lat_best_model_v1.h5'\n",
    "\n",
    "## Checkpoint save - lon\n",
    "checkpoint_filepath_lon = r'D:\\2 Thesis\\2 models\\2023.07.02 all models\\GRU_02\\best model normal ds\\gru_lon_best_model_v1.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_lat = DataGenerator(X_train, Y_train_lat, 200)\n",
    "val_gen_lat = DataGenerator(X_val, Y_val_lat, 200)\n",
    "\n",
    "train_gen_lon = DataGenerator(X_train, Y_train_lon, 200)\n",
    "val_gen_lon = DataGenerator(X_val, Y_val_lon, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the GRU model\n",
    "def gru_model(n_steps_input, n_steps_output, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(20, activation=\"tanh\", input_shape=(n_steps_input, n_features), return_sequences=True))\n",
    "    model.add(GRU(40, activation=\"tanh\"))\n",
    "    model.add(Dense(n_steps_output))  \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary = gru_model(10,10,8).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lat = gru_model(n_steps_input = 10, n_steps_output = 10  , n_features = 8 )\n",
    "# Compile the model\n",
    "model_lat.compile(optimizer= Adam(learning_rate = 0.0001), loss = 'mean_squared_error', metrics=['mae'] )\n",
    "checkpoint_lat = ModelCheckpoint(checkpoint_filepath_lat, monitor='val_loss', save_best_only=True, mode='min')\n",
    "# Train the model\n",
    "history_lat = model_lat.fit(train_gen_lat, validation_data = val_gen_lat, epochs=10, verbose=1, callbacks = [checkpoint_lat])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(history_lat.history['loss'], label='Training loss')\n",
    "plt.plot(history_lat.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation error\n",
    "plt.plot(history_lat.history['mae'], label='Training error')\n",
    "plt.plot(history_lat.history['val_mae'], label='Validation error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading best latitude model\n",
    "best_model_lat = load_model(checkpoint_filepath_lat)\n",
    "# Evaluate the model\n",
    "Y_test_pred_lat = best_model_lat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_lat = Y_test_lat.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lat = mean_squared_error(Y_test_lat, Y_test_pred_lat)\n",
    "print(\"Mean Squared Error for lat predictions:\", mse_lat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LONGITUDE PREDICTIONS - GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lon = gru_model(n_steps_input = 10, n_steps_output = 10  , n_features = 8 )\n",
    "\n",
    "model_lon.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'mean_squared_error', metrics=['mae'])\n",
    "checkpoint_lon = ModelCheckpoint(checkpoint_filepath_lon, monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "history_lon = model_lon.fit(train_gen_lon, validation_data = val_gen_lon, epochs=10, verbose=1 , callbacks = [checkpoint_lon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(history_lon.history['loss'], label='Training loss')\n",
    "plt.plot(history_lon.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation error\n",
    "plt.plot(history_lon.history['mae'], label='Training error')\n",
    "plt.plot(history_lon.history['val_mae'], label='Validation error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading best longitude model\n",
    "best_model_lon = load_model(checkpoint_filepath_lon)\n",
    "# Evaluate the model\n",
    "Y_test_pred_lon = best_model_lon.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalize shapes\n",
    "Y_test_lon = Y_test_lon.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lon = mean_squared_error(Y_test_lon, Y_test_pred_lon)\n",
    "print(\"Mean Squared Error Y_test_pred_lon:\", mse_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lat_flat = Y_test_pred_lat.flatten()\n",
    "Y_pred_lat_df = pd.DataFrame(Y_pred_lat_flat, columns=['lat_s_pred'])\n",
    "\n",
    "Y_pred_lon_flat = Y_test_pred_lon.flatten()\n",
    "Y_pred_lon_df = pd.DataFrame(Y_pred_lon_flat, columns=['lon_s_pred'])\n",
    "\n",
    "Y_pred_df = pd.concat([Y_pred_lat_df, Y_pred_lon_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_lat_flat = Y_test_lat.flatten()\n",
    "Y_test_lat_df = pd.DataFrame(Y_test_lat_flat, columns=['lat_s_test'])\n",
    "\n",
    "Y_test_lon_flat = Y_test_lon.flatten()\n",
    "Y_test_lon_df = pd.DataFrame(Y_test_lon_flat, columns=['lon_s_test'])\n",
    "\n",
    "Y_test_df = pd.concat([Y_test_lat_df, Y_test_lon_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting back to lat long degrees\n",
    "\n",
    "min_lat, max_lat = 58.6, 59.93\n",
    "min_lon, max_lon = 9.4, 11.45\n",
    "\n",
    "Y_pred_df['lat_pred'] = Y_pred_df['lat_s_pred'] * (max_lat - min_lat) + min_lat\n",
    "Y_pred_df['lon_pred'] = Y_pred_df['lon_s_pred'] * (max_lon - min_lon) + min_lon\n",
    "\n",
    "Y_test_df['lat_test'] = Y_test_df['lat_s_test'] * (max_lat - min_lat) + min_lat\n",
    "Y_test_df['lon_test'] = Y_test_df['lon_s_test'] * (max_lon - min_lon) + min_lon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_and_pred_df = pd.concat([Y_pred_df, Y_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine, Unit\n",
    "\n",
    "Y_test_and_pred_df['deviation_dist_m'] = Y_test_and_pred_df.apply(lambda row: haversine(\n",
    "    (row['lat_pred'], \n",
    "    row['lon_pred']),\n",
    "    (row['lat_test'], \n",
    "    row['lon_test']),\n",
    "    unit=Unit.METERS\n",
    "    ),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_deviation = Y_test_and_pred_df['deviation_dist_m'].mean()\n",
    "median_deviation = Y_test_and_pred_df['deviation_dist_m'].median()\n",
    "\n",
    "print('GRU_model mean_displacement_error:', mean_deviation)\n",
    "print('GRU_model median_displacement_error:', median_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_means = []\n",
    "for step in range(10):\n",
    "    step_mean = Y_test_and_pred_df['deviation_dist_m'][step::9].mean()\n",
    "    step_means.append(step_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step_means = []\n",
    "for step in range(10):\n",
    "    step_mean = Y_test_and_pred_df['deviation_dist_m'][step::9].mean()\n",
    "    step_means.append(step_mean)\n",
    "\n",
    "plt.plot(range(1, 11), step_means)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Mean Error (m)')\n",
    "plt.title('Mean Error for each prediction step')\n",
    "# plt.ylim(0, 200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "step_medians = []\n",
    "for step in range(10):\n",
    "    step_median = Y_test_and_pred_df['deviation_dist_m'][step::9].median()\n",
    "    step_medians.append(step_median)\n",
    "\n",
    "plt.plot(range(1, 11), step_medians)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Median Error (m)')\n",
    "plt.title('Median Error for each prediction step')\n",
    "# plt.ylim(0,125)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step_FDE = Y_test_and_pred_df['deviation_dist_m'][9::9].mean()\n",
    "print('Final displacement error (meters) is:', step_FDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_and_pred_df['voyage_id'] = Y_test_and_pred_df.index // 10\n",
    "Y_test_and_pred_df['step'] = np.arange(len(Y_test_and_pred_df)) % 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_and_pred_df.to_csv(to_store_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
